{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "from pycoral.adapters import classify\n",
    "from pycoral.adapters import common\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from imgaug import augmenters as img_aug\n",
    "\n",
    "from lane_navigation.image_augmentation import random_augment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_imread(image_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    return image\n",
    "\n",
    "\n",
    "def img_preprocess(image):\n",
    "    height, _, _ = image.shape\n",
    "    image = image[\n",
    "        int(height / 2) :, :, :\n",
    "    ]  # remove top half of the image, as it is not relavant for lane following\n",
    "    image = cv2.cvtColor(\n",
    "        image, cv2.COLOR_RGB2YUV\n",
    "    )  # Nvidia model said it is best to use YUV color space\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    image = cv2.resize(image, (200, 66))  # input image size (200,66) Nvidia model\n",
    "    image = (\n",
    "        image / 255\n",
    "    )  # normalizing, the processed image becomes black for some reason.  do we need this?\n",
    "    # image = image.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_data_generator(image_paths, batch_size, is_training):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_steering_angles = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "            image_path = image_paths[random_index]\n",
    "            image = my_imread(image_paths[random_index])\n",
    "            if is_training:\n",
    "                # training: augment image\n",
    "                image, steering_angle = random_augment(image, steering_angle)\n",
    "\n",
    "            image = img_preprocess(image)\n",
    "            batch_images.append(image)\n",
    "\n",
    "        yield np.asarray(batch_images)\n",
    "\n",
    "\n",
    "def set_input_tensor(interpreter, input):\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    tensor_index = input_details[\"index\"]\n",
    "    input_tensor = interpreter.tensor(tensor_index)()\n",
    "    # Inputs for the TFLite model must be uint8, so we quantize our input data.\n",
    "    scale, zero_point = input_details[\"quantization\"]\n",
    "    quantized_input = np.uint8(input / (scale) + zero_point)\n",
    "    input_tensor[0][:, :] = quantized_input\n",
    "\n",
    "\n",
    "def predict_steer(interpreter, input):\n",
    "    set_input_tensor(interpreter, input)\n",
    "    # common.set_input(interpreter, input)\n",
    "    interpreter.invoke()\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    output_data = interpreter.tensor(output_details[\"index\"])().flatten()\n",
    "\n",
    "    if np.issubdtype(output_details[\"dtype\"], np.integer):\n",
    "        scale, zero_point = output_details[\"quantization\"]\n",
    "        # Always convert to np.int64 to avoid overflow on subtraction.\n",
    "        return scale * (output_data.astype(np.int64) - zero_point)\n",
    "\n",
    "    return output_data\n",
    "\n",
    "\n",
    "def predict_with_keras(model, image):\n",
    "    return model.predict(image)[0]\n",
    "\n",
    "\n",
    "def predict_with_tflite(model_path, image):\n",
    "    interpreter = tflite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    return predict_steer(interpreter, image)\n",
    "\n",
    "\n",
    "def predict_with_edgetpu(model_path, image):\n",
    "    interpreter = make_interpreter(\n",
    "        \"lane_navigation/model/lane_navigation_w_pretrain_final.tflite\"\n",
    "    )\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    return predict_steer(interpreter, image)\n",
    "\n",
    "\n",
    "def convert_keras_to_tflite(image_paths, model, dst_path):\n",
    "    def representative_data_gen():\n",
    "        input_data = tf.cast(\n",
    "            next(image_data_generator(image_paths, 200, False)), dtype=tf.float32\n",
    "        )\n",
    "        yield [input_data]\n",
    "\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.target_spec.supported_types = [tf.int8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(dst_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "\n",
    "def convert_tflite_to_edgetpu(model_path):\n",
    "    dst_dir = str(Path(model_path).parent)\n",
    "    cmd = f\"edgetpu_compiler -a -o {dst_dir} {model_path}\"\n",
    "    result = subprocess.check_output(cmd, shell=True)\n",
    "    print(result.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "lab_dirs = list(Path(\"train_data_generation/data/drive_with_keypress/\").glob(\"*\"))\n",
    "for lab_dir in lab_dirs:\n",
    "    frame_paths = list(lab_dir.glob(\"*.png\"))\n",
    "    for frame_path in frame_paths:\n",
    "        image_paths.append(frame_path)\n",
    "image_paths.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference___call___32344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_97451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_77595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_103456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_93843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_107064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_75975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"objects_on_road_processor/model/efficientdet_d0_coco17_tpu-32/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lane_navigation/model/lane_navigation_w_pretrain_final.h5\"\n",
    "tflite_model_path = \"lane_navigation/model/lane_navigation_w_pretrain_final.tflite\"\n",
    "edgetpu_model_path = (\n",
    "    \"lane_navigation/model/lane_navigation_w_pretrain_final_edgetpu.tflite\"\n",
    ")\n",
    "\n",
    "keras_model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_keras_to_tflite(image_paths, keras_model, tflite_model_path)\n",
    "convert_tflite_to_edgetpu(tflite_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000508_47.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000400_58.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/31/frame_000071_69.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000866_72.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000277_81.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/28/frame_000017_90.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/31/frame_000005_107.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000160_113.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000102_131.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000125_135.png\",\n",
    "]\n",
    "image = my_imread(test_image_paths[4])\n",
    "proc_image = np.asarray([img_preprocess(image)])\n",
    "plt.imshow(proc_image[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in test_image_paths:\n",
    "    image = my_imread(image_path)\n",
    "    proc_image = np.asarray([img_preprocess(image)])\n",
    "\n",
    "    print(image_path)\n",
    "    print(predict_with_keras(keras_model, proc_image))\n",
    "    print(predict_with_tflite(tflite_model_path, proc_image))\n",
    "    print(predict_with_edgetpu(edgetpu_model_path, proc_image))\n",
    "    print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_coral",
   "language": "python",
   "name": "tf_coral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c45dd15ca332e50a83ca69c221c3167dbe2f5e61615061c146cddebbcf16ac7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
