{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from imgaug import augmenters as img_aug\n",
    "\n",
    "from lane_navigation.image_augmentation import random_augment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 12:45:18.784387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-06 12:45:18.784996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-06 12:45:18.785496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-06 12:45:18.785994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-06 12:45:18.786450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-06 12:45:18.786888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9920 MB memory:  -> device: 0, name: GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot parse file objects_on_road_processor/model/ssd_mobilenet_v2/out/model.ckpt-30792.meta: 1:1 : Message type \"tensorflow.MetaGraphDef\" has no field named \"version\"..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mread_meta_graph_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m     \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mMerge\u001b[0;34m(text, message, allow_unknown_extension, allow_field_number, descriptor_pool, allow_unknown_field)\u001b[0m\n\u001b[1;32m    718\u001b[0m   \"\"\"\n\u001b[0;32m--> 719\u001b[0;31m   return MergeLines(\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'\\n'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mu'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mMergeLines\u001b[0;34m(lines, message, allow_unknown_extension, allow_field_number, descriptor_pool, allow_unknown_field)\u001b[0m\n\u001b[1;32m    792\u001b[0m                    allow_unknown_field=allow_unknown_field)\n\u001b[0;32m--> 793\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mMergeLines\u001b[0;34m(self, lines, message)\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_multiple_scalars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ParseOrMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_ParseOrMerge\u001b[0;34m(self, lines, message)\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_unknown_field\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         raise tokenizer.ParseErrorPreviousToken(\n\u001b[0m\u001b[1;32m    933\u001b[0m             \u001b[0;34m'Message type \"%s\" has no field named \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseError\u001b[0m: 1:1 : Message type \"tensorflow.MetaGraphDef\" has no field named \"version\".",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_107627/2219728069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Restore from checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_checkpoint_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_checkpoint_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \"\"\"  # pylint: disable=g-doc-exception\n\u001b[0;32m-> 1565\u001b[0;31m   return _import_meta_graph_with_return_elements(meta_graph_or_file,\n\u001b[0m\u001b[1;32m   1566\u001b[0m                                                  \u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                                  **kwargs)[0]\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                        \"execution is enabled.\")\n\u001b[1;32m   1580\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_meta_graph_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_or_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf_coral/lib/python3.8/site-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mread_meta_graph_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot parse file {filename}: {str(e)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot parse file objects_on_road_processor/model/ssd_mobilenet_v2/out/model.ckpt-30792.meta: 1:1 : Message type \"tensorflow.MetaGraphDef\" has no field named \"version\".."
     ]
    }
   ],
   "source": [
    "trained_checkpoint_prefix = 'objects_on_road_processor/model/ssd_mobilenet_v2/out/model.ckpt-30792'\n",
    "export_dir = 'objects_on_road_processor/model/ssd_mobilenet_v2/pb_out'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    # Restore from checkpoint\n",
    "    loader = tf.compat.v1.train.import_meta_graph(\"objects_on_road_processor/model/ssd_mobilenet_v2/out/model.ckpt-30792.meta\")\n",
    "    loader.restore(sess, tf.train.latest_checkpoint('objects_on_road_processor/model/ssd_mobilenet_v2/out'))\n",
    "\n",
    "    # Export checkpoint to SavedModel\n",
    "    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                         [tf.saved_model.TRAINING, tf.saved_model.SERVING],\n",
    "                                         strip_default_attrs=True)\n",
    "    builder.save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_imread(image_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    return image\n",
    "\n",
    "\n",
    "def img_preprocess(image):\n",
    "    height, _, _ = image.shape\n",
    "    image = image[\n",
    "        int(height / 2) :, :, :\n",
    "    ]  # remove top half of the image, as it is not relavant for lane following\n",
    "    image = cv2.cvtColor(\n",
    "        image, cv2.COLOR_RGB2YUV\n",
    "    )  # Nvidia model said it is best to use YUV color space\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    image = cv2.resize(image, (200, 66))  # input image size (200,66) Nvidia model\n",
    "    image = (\n",
    "        image / 255\n",
    "    )  # normalizing, the processed image becomes black for some reason.  do we need this?\n",
    "    # image = image.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_data_generator(image_paths, batch_size, is_training):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_steering_angles = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "            image_path = image_paths[random_index]\n",
    "            image = my_imread(image_paths[random_index])\n",
    "            if is_training:\n",
    "                # training: augment image\n",
    "                image, steering_angle = random_augment(image, steering_angle)\n",
    "\n",
    "            image = img_preprocess(image)\n",
    "            batch_images.append(image)\n",
    "\n",
    "        yield np.asarray(batch_images)\n",
    "\n",
    "\n",
    "def set_input_tensor(interpreter, input):\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    tensor_index = input_details[\"index\"]\n",
    "    input_tensor = interpreter.tensor(tensor_index)()\n",
    "    # Inputs for the TFLite model must be uint8, so we quantize our input data.\n",
    "    scale, zero_point = input_details[\"quantization\"]\n",
    "    quantized_input = np.uint8(input / (scale) + zero_point)\n",
    "    input_tensor[0][:, :] = quantized_input\n",
    "\n",
    "\n",
    "def predict_steer(interpreter, input):\n",
    "    set_input_tensor(interpreter, input)\n",
    "    # common.set_input(interpreter, input)\n",
    "    interpreter.invoke()\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    output_data = interpreter.tensor(output_details[\"index\"])().flatten()\n",
    "\n",
    "    if np.issubdtype(output_details[\"dtype\"], np.integer):\n",
    "        scale, zero_point = output_details[\"quantization\"]\n",
    "        # Always convert to np.int64 to avoid overflow on subtraction.\n",
    "        return scale * (output_data.astype(np.int64) - zero_point)\n",
    "\n",
    "    return output_data\n",
    "\n",
    "\n",
    "def predict_with_keras(model, image):\n",
    "    return model.predict(image)[0]\n",
    "\n",
    "\n",
    "def predict_with_tflite(model_path, image):\n",
    "    interpreter = tflite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    return predict_steer(interpreter, image)\n",
    "\n",
    "\n",
    "def predict_with_edgetpu(model_path, image):\n",
    "    interpreter = make_interpreter(\n",
    "        \"lane_navigation/model/lane_navigation_w_pretrain_final.tflite\"\n",
    "    )\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    return predict_steer(interpreter, image)\n",
    "\n",
    "\n",
    "def convert_keras_to_tflite(image_paths, model, dst_path):\n",
    "    def representative_data_gen():\n",
    "        input_data = tf.cast(\n",
    "            next(image_data_generator(image_paths, 200, False)), dtype=tf.float32\n",
    "        )\n",
    "        yield [input_data]\n",
    "\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.target_spec.supported_types = [tf.int8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(dst_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "\n",
    "def convert_tflite_to_edgetpu(model_path):\n",
    "    dst_dir = str(Path(model_path).parent)\n",
    "    cmd = f\"edgetpu_compiler -a -o {dst_dir} {model_path}\"\n",
    "    result = subprocess.check_output(cmd, shell=True)\n",
    "    print(result.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "lab_dirs = list(Path(\"train_data_generation/data/drive_with_keypress/\").glob(\"*\"))\n",
    "for lab_dir in lab_dirs:\n",
    "    frame_paths = list(lab_dir.glob(\"*.png\"))\n",
    "    for frame_path in frame_paths:\n",
    "        image_paths.append(frame_path)\n",
    "image_paths.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference___call___32344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_97451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_77595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_103456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_93843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_107064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_75975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"objects_on_road_processor/model/efficientdet_d0_coco17_tpu-32/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lane_navigation/model/lane_navigation_w_pretrain_final.h5\"\n",
    "tflite_model_path = \"lane_navigation/model/lane_navigation_w_pretrain_final.tflite\"\n",
    "edgetpu_model_path = (\n",
    "    \"lane_navigation/model/lane_navigation_w_pretrain_final_edgetpu.tflite\"\n",
    ")\n",
    "\n",
    "keras_model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_keras_to_tflite(image_paths, keras_model, tflite_model_path)\n",
    "convert_tflite_to_edgetpu(tflite_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000508_47.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000400_58.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/31/frame_000071_69.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000866_72.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000277_81.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/28/frame_000017_90.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/31/frame_000005_107.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000160_113.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000102_131.png\",\n",
    "    \"train_data_generation/data/drive_with_keypress/30/frame_000125_135.png\",\n",
    "]\n",
    "image = my_imread(test_image_paths[4])\n",
    "proc_image = np.asarray([img_preprocess(image)])\n",
    "plt.imshow(proc_image[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in test_image_paths:\n",
    "    image = my_imread(image_path)\n",
    "    proc_image = np.asarray([img_preprocess(image)])\n",
    "\n",
    "    print(image_path)\n",
    "    print(predict_with_keras(keras_model, proc_image))\n",
    "    print(predict_with_tflite(tflite_model_path, proc_image))\n",
    "    print(predict_with_edgetpu(edgetpu_model_path, proc_image))\n",
    "    print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_coral",
   "language": "python",
   "name": "tf_coral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c45dd15ca332e50a83ca69c221c3167dbe2f5e61615061c146cddebbcf16ac7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
